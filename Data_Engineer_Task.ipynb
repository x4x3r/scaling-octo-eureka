{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7128548f",
   "metadata": {},
   "source": [
    "# Movies analysis using Python Pandas and Object-oriented Approach (OOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2a99c",
   "metadata": {},
   "source": [
    "The code in this notebook analyses the movies dataset downloaded from https://www.kaggle.com/rounakbanik/the-movies-dataset by using the data from the `movies_metadata.csv` and `ratings.csv` files according to the requirements specified in the file [Data_Engineering_Task.txt](https://github.com/x4x3r/scaling-octo-eureka/blob/main/Data-Engineer_task.txt).\n",
    "\n",
    "Solutions to the data engineering task are given in point 1-7.\n",
    "\n",
    "Refer to point **8. Movies analysis program using Pandas and object-oriented approach (OOP)** for the object-oriented (OOP) solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e6578",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa61f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd65219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory named \"data\" and unzip the downloaded movies data\n",
    "!mkdir '/home/user/Desktop/data_engineering_task/data'\n",
    "!unzip 'archive.zip' -d '/home/user/Desktop/data_engineering_task/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the unzipped data\n",
    "%ls -l data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba8a4ce",
   "metadata": {},
   "source": [
    "## Data exploration and  processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764ed21",
   "metadata": {},
   "source": [
    "The number of movies can be calculated from the `movies_metadata.csv` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e4344",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#  Read the movies_metadata.csv dataset into a pandas DataFrame\n",
    "movies_df = pd.read_csv('data/movies_metadata.csv', header=0)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame to get a glimpse of the data\n",
    "movies_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genres'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which columns can be used for counting the movies\n",
    "movies_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f560d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the total number of rows in the movies metadata dataset\n",
    "len(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd95dff",
   "metadata": {},
   "source": [
    "**Explanation**: There are 45466 rows in the movies_metadata.csv. `movies_df.columns` reveals that there are 2 possible id columns: 'id' and 'imdb_id'. Further inspection reveals that 'id' has more values and no NA values, while the index numbers in 'imdb_id' have 17 movies less. So, 'id' column might be appropriate for movie count and as an id column of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8d9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the 'id' column that have NA values\n",
    "movies_df['id'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ab052",
   "metadata": {},
   "source": [
    "**Explanation**: There are no rows in the 'id' column with NA values, indicating that it is a complete and suitable column for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c2973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of rows in the 'imdb_id' column that have NA values\n",
    "movies_df['imdb_id'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ab0eb",
   "metadata": {},
   "source": [
    "**Explanation**: There are 17 movies in the dataset that are not indexed by IMDB but still exist in the movies database on Kaggle. These movies have missing values in the 'imdb_id' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5460838c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the 17 movies that have missing 'imdb_id' values\n",
    "movies_df[movies_df['imdb_id'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085c049",
   "metadata": {},
   "source": [
    "**Explanation**: The above DataFrame shows the 17 movies that do not have an 'imdb_id'. These movies might have limited information available, making it difficult to use them in further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c786b9",
   "metadata": {},
   "source": [
    "Also, `pd.read_csv` returns **DtypeWarning: Columns (10) have mixed types**. Columns (10) is the 'id' column. We will try to filter these non-alphanumeric symbols to see what's in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c0794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out the rows in the 'id' column that contain non-alphanumeric symbols\n",
    "movies_df[~movies_df['id'].str.isalnum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bc2548",
   "metadata": {},
   "source": [
    "**Explanation**: The 'id' column contains three rows with release dates instead of alphanumeric values. Since these rows do not provide much useful information and lack proper 'id' numbers, it is best to drop them from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2282806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the non-alphanumeric rows\n",
    "movies_df = movies_df[movies_df['id'].str.isalnum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4aebb",
   "metadata": {},
   "source": [
    "Also, it's worthwile checking for duplicate rows. Here are they:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98b9550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows in the 'id' column\n",
    "movies_df[movies_df['id'].duplicated(keep=False)].sort_values('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d69af",
   "metadata": {},
   "source": [
    "**Explanation**: The above DataFrame displays the rows in the 'id' column that are duplicated. It helps identify any inconsistencies or redundant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bac343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the rows with unique 'id' numbers and update the dataframe\n",
    "movies_df = movies_df.drop_duplicates(subset='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae9dbe",
   "metadata": {},
   "source": [
    "## 1. Load the dataset from a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5becd4a7",
   "metadata": {},
   "source": [
    "We can write all data processing operations as a single function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88dbd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(ratings_filepath, movies_filepath):\n",
    "    \"\"\"1. Load the dataset from a CSV file.\"\"\"\n",
    "    \n",
    "    dtypes = {\n",
    "        'genres': object,\n",
    "        'release_date': str,\n",
    "        'title': str,\n",
    "    }\n",
    "    \n",
    "    # Read the movies_metadata.csv\n",
    "    movie_columns = ['genres', 'id', 'release_date', 'title']\n",
    "    movies_df = pd.read_csv(movies_filepath, header=0 , sep=',', \\\n",
    "                            parse_dates=True, \\\n",
    "                            usecols=movie_columns, \\\n",
    "                            dtype=dtypes)\n",
    "    \n",
    "    # Drop the rows in movies_df where 'id' column contains non-alphanumeric symbols\n",
    "    movies_df = movies_df[movies_df['id'].str.isalnum()]\n",
    "    \n",
    "    # Keep only the rows with unique 'id' numbers\n",
    "    movies_df = movies_df.drop_duplicates(subset='id')\n",
    "    \n",
    "    # Convert 'id' column to int data type\n",
    "    movies_df['id'] = movies_df['id'].astype(int)\n",
    "    \n",
    "    # Set the 'id' column as the index of movies_df\n",
    "    movies_df.set_index('id', inplace=True)  \n",
    "    \n",
    "    # Read the ratings.csv file into ratings_df DataFrame\n",
    "    columns = ['movieId', 'rating']\n",
    "    ratings_df = pd.read_csv(ratings_filepath, \\\n",
    "                        usecols=columns, \\\n",
    "                        index_col='movieId', \\\n",
    "                         dtype={'movieId':int, \\\n",
    "                        'rating':float}, \\\n",
    "                            nrows=10000)\n",
    "    \n",
    "    return ratings_df, movies_df\n",
    "\n",
    "ratings_filepath = os.getcwd() + '/' + 'data/ratings.csv'\n",
    "movies_filepath = os.getcwd() + '/' + 'data/movies_metadata.csv'\n",
    "\n",
    "ratings_df, movies_df = data_processing(ratings_filepath, movies_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61b99d",
   "metadata": {},
   "source": [
    "## 2. Print the number of movies in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6a429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the number of unique movies\n",
    "len(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a77bd2",
   "metadata": {},
   "source": [
    "## 3. Print the average rating of all the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685fcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating_loops(file_path):\n",
    "    \"\"\"Calculate the average rating of all movies\"\"\"\n",
    "        \n",
    "    # Define the variables\n",
    "    chunk_size= 5000\n",
    "    \n",
    "    # Initialize variables for average rating calculation\n",
    "    total_sum = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Read the file in chunks to prevent memory overloading\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        chunk_sum = chunk['rating'].sum()\n",
    "        \n",
    "        # Update the average values\n",
    "        total_sum += chunk_sum\n",
    "        total_count += len(chunk)\n",
    "    \n",
    "    # Calculate the average rating for all movies\n",
    "    average_rating = total_sum/total_count\n",
    "    \n",
    "    # Print the average rating of all the movies\n",
    "    print('Average movie rating: ' + str(np.round(average_rating, 2)))\n",
    "\n",
    "file_path='data/ratings.csv'\n",
    "average_rating_loops(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4773053",
   "metadata": {},
   "source": [
    "Another way is to use Pandas load only the columns necessary for calculating the average rating of all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704b4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_rating(ratings):\n",
    "    \"\"\"Calculate the average rating of all movies\"\"\"\n",
    "    \n",
    "    average_rating = ratings_df['rating'].mean()\n",
    "    print('Average movie rating: ' + str(np.round(average_rating, 2)))\n",
    "\n",
    "average_rating(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb52c7f",
   "metadata": {},
   "source": [
    "## 4. Print the top 5 highest rated movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59360d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Barton Fink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Lucky You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Marnie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47122</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Flaming Creatures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Bill &amp; Ted's Bogus Journey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rating                       title\n",
       "290       5.0                 Barton Fink\n",
       "1950      5.0                   Lucky You\n",
       "506       5.0                      Marnie\n",
       "47122     5.0           Flaming Creatures\n",
       "1649      5.0  Bill & Ted's Bogus Journey"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_5_movies(movies, ratings):\n",
    "    \"\"\"4. Print the top 5 highest rated movies.\"\"\"\n",
    "    \n",
    "    # Calculate the average ratign by movieId\n",
    "    avg_ratings_df = ratings.groupby('movieId').apply('mean', 'rating')\n",
    "    \n",
    "    # Merge the dataframes based on ratingsmovieId and id\n",
    "    merged_df = pd.merge(avg_ratings_df, movies, left_index=True, right_index=True)\n",
    "    \n",
    "    # Calculate the top 5 movies\n",
    "    top_5_movies = merged_df[['rating', 'title']].sort_values('rating', ascending=False).head(5)\n",
    "    \n",
    "    return top_5_movies\n",
    "\n",
    "result = top_5_movies(movies=movies_df, ratings=ratings_df)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c3cc83",
   "metadata": {},
   "source": [
    "This code can be improved by using weightened average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd8628d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "1D weights expected when shapes of a and weights differ.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1353\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m     \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m     \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03mApply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m    data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtop_5_movies.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     avg_rating = ratings.groupby(ratings.index)['rating'].apply(lambda x: np.average(a=x.rating, weights=weights))\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     avg_rating \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mgroupby(ratings\u001b[38;5;241m.\u001b[39mindex)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Merge the dataframes based on the index\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     avg_ratings_df = pd.DataFrame(avg_rating, index=ratings.index, columns=['avg_rating'])\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/numpy/lib/function_base.py:536\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wgt\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1D weights expected when shapes of a and weights differ.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]:\n",
      "\u001b[0;31mTypeError\u001b[0m: 1D weights expected when shapes of a and weights differ.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_5_movies\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Assuming you have your ratings and movies DataFrames defined, call the function like this:\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtop_5_movies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mratings_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmovies_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtop_5_movies\u001b[0;34m(ratings, movies)\u001b[0m\n\u001b[1;32m      8\u001b[0m     weights \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mgroupby(ratings\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     avg_rating = ratings.groupby(ratings.index)['rating'].apply(lambda x: np.average(a=x.rating, weights=weights))\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     avg_rating \u001b[38;5;241m=\u001b[39m \u001b[43mratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Merge the dataframes based on the index\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     avg_ratings_df = pd.DataFrame(avg_rating, index=ratings.index, columns=['avg_rating'])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(avg_ratings_df, movies, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/generic.py:216\u001b[0m, in \u001b[0;36mSeriesGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(\n\u001b[1;32m    211\u001b[0m     _apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries\u001b[39m\u001b[38;5;124m\"\u001b[39m, examples\u001b[38;5;241m=\u001b[39m_apply_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_examples\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     )\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1363\u001b[0m, in \u001b[0;36mGroupBy.apply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_apply_general(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj)\n\u001b[1;32m   1354\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1355\u001b[0m         \u001b[38;5;66;03m# gh-20949\u001b[39;00m\n\u001b[1;32m   1356\u001b[0m         \u001b[38;5;66;03m# try again, with .apply acting as a filtering\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[38;5;66;03m# fails on *some* columns, e.g. a numeric operation\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;66;03m# on a string grouper column\u001b[39;00m\n\u001b[0;32m-> 1363\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:1402\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     is_agg: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1375\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1378\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1402\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1404\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/pandas/core/groupby/ops.py:767\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    766\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 767\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    769\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m, in \u001b[0;36mtop_5_movies.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     weights \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mgroupby(ratings\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     avg_rating = ratings.groupby(ratings.index)['rating'].apply(lambda x: np.average(a=x.rating, weights=weights))\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     avg_rating \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mgroupby(ratings\u001b[38;5;241m.\u001b[39mindex)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Merge the dataframes based on the index\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     avg_ratings_df = pd.DataFrame(avg_rating, index=ratings.index, columns=['avg_rating'])\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(avg_ratings_df, movies, left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/venvs/adastra/lib/python3.8/site-packages/numpy/lib/function_base.py:536\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAxis must be specified when shapes of a and weights \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiffer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wgt\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1D weights expected when shapes of a and weights differ.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[axis]:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of weights not compatible with specified axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 1D weights expected when shapes of a and weights differ."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def top_5_movies(ratings, movies):\n",
    "    \"\"\"Print the top 5 highest-rated movies\"\"\"\n",
    "\n",
    "    # Group by 'movieId' and calculate the weighted average\n",
    "    weights = ratings.groupby(ratings.index).transform('count')\n",
    "#     avg_rating = ratings.groupby(ratings.index)['rating'].apply(lambda x: np.average(a=x.rating, weights=weights))\n",
    "    avg_rating = ratings.groupby(ratings.index)['rating'].apply(lambda x: np.average(a=x, weights=weights, \\\n",
    "                                                                                     axis=0 ))\n",
    "\n",
    "    # Merge the dataframes based on the index\n",
    "#     avg_ratings_df = pd.DataFrame(avg_rating, index=ratings.index, columns=['avg_rating'])\n",
    "    merged_df = pd.merge(avg_ratings_df, movies, left_index=True, right_index=True)\n",
    "\n",
    "    # Get the top 5 movies\n",
    "    top_5_movies = merged_df[['avg_rating', 'title']].sort_values(by='avg_rating', ascending=False).head(5)\n",
    "\n",
    "    return top_5_movies\n",
    "\n",
    "# Assuming you have your ratings and movies DataFrames defined, call the function like this:\n",
    "result = top_5_movies(ratings=ratings_df, movies=movies_df)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b022bc",
   "metadata": {},
   "source": [
    "## 5. Print the number of movies released each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movies_per_year(movies):\n",
    "    \"\"\"Print the number of movies per year\"\"\"\n",
    "    \n",
    "    # Extract the year component from 'release_date' and store into a new column 'release_year'\n",
    "    movies['release_year'] = pd.to_datetime(movies['release_date'], errors='coerce').dt.year\n",
    "    \n",
    "    # Dropping the na in 'release_year'\n",
    "    movies['release_year'] = movies['release_year'].dropna()\n",
    "    \n",
    "    # Count the number of movies released each year\n",
    "    movies_per_year = movies['release_year'].value_counts().sort_index()\n",
    "    \n",
    "    # Create a movies_per_year_df DataFrame from the Pandas Series\n",
    "    movies_per_year_df = pd.DataFrame({'Year': movies_per_year.index, 'Count': movies_per_year.values})\n",
    "    \n",
    "    # Cast 'Year' column to integer data type\n",
    "    movies_per_year_df['Year'] = movies_per_year_df['Year'].astype(int)\n",
    "    \n",
    "    return movies_per_year_df\n",
    "    \n",
    "n_movies = movies_per_year(movies_df)\n",
    "\n",
    "n_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc59519a",
   "metadata": {},
   "source": [
    "## 6. Print the number of movies in each genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a91e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def movies_per_genre(movies):\n",
    "    \"\"\"Print the number of movies in each genre\"\"\"\n",
    "    \n",
    "    # Convert the string stored in column 'genres' to lists of dictionaries\n",
    "    # movies_df['genres'] = movies_df['genres'].apply(ast.literal_eval)\n",
    "    if isinstance(movies_df['genres'].iloc[0], str):\n",
    "        movies_df['genres'] = movies_df['genres'].apply(ast.literal_eval)\n",
    "\n",
    "    # Extract the relevant information from the nested dictionaries\n",
    "    movies_df['genre_names'] = movies_df['genres'].apply(lambda x: [genre['name'] for genre in x])\n",
    "    \n",
    "    # Count the number of movies per genre and return a pandas.DataFrame\n",
    "    movies_per_genre = movies_df['genre_names'].explode().value_counts()\n",
    "    movies_per_genre.columns = ['Genre', 'Count']\n",
    "    \n",
    "    return movies_per_genre.to_frame().reset_index()\n",
    "\n",
    "movies_per_genre(movies=movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4d757",
   "metadata": {},
   "source": [
    "## 7. Save the dataset to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_movies.to_json('path/to/top_5_movies.csv')\n",
    "movies_per_year.to_json('path/to/movies_per_year.csv')\n",
    "movies_per_genre.to_json('path/to/movies_per_genre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545114e",
   "metadata": {},
   "source": [
    "## 8. Program to analyse the movies dataset using Pandas and object-oriented approach (OOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d6e92",
   "metadata": {},
   "source": [
    "This program can be used in this notebook and as a standalone application to print the results in the console window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577de7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from datetime import datetime, date\n",
    "\n",
    "\n",
    "class MoviesAnalisys():\n",
    "    \"\"\"Data analysis of the movies dataset\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, movies_filepath, ratings_filepath):\n",
    "        \"\"\"Initialize attributes\"\"\"\n",
    "        \n",
    "        # 1. Load the dataset from a CSV file.\n",
    "        # Define the data types for each column\n",
    "        dtypes_movies = {\n",
    "            'genres': object,\n",
    "            'release_date': str,\n",
    "            'title': str,\n",
    "        }\n",
    "        \n",
    "        # Read the movies_metadata.csv file\n",
    "        movies_columns = ['genres', 'id', 'release_date', 'title']\n",
    "        self.movies = pd.read_csv(movies_filepath, header=0, sep=',', \\\n",
    "                        parse_dates=True, \\\n",
    "                        usecols=movies_columns, \\\n",
    "                        dtype=dtypes_movies)\n",
    "        \n",
    "        # Drop the non-alphanumeric rows\n",
    "        self.movies = self.movies[self.movies['id'].str.isalnum()]\n",
    "        \n",
    "        # Keep only the rows with unique 'id' numbers\n",
    "        self.movies = self.movies.drop_duplicates(subset='id')\n",
    "        \n",
    "        # Convert 'id' column to int data type\n",
    "        self.movies['id'] = self.movies['id'].astype(int)\n",
    "        \n",
    "        # Set the 'id' column as self.movies index\n",
    "        self.movies.set_index('id', inplace=True)  \n",
    "        \n",
    "        ratings_columns = ['movieId', 'rating']\n",
    "        self.ratings = pd.read_csv(ratings_filepath, \\\n",
    "                                usecols=ratings_columns, \\\n",
    "                                index_col='movieId', \\\n",
    "                                dtype={'movieId': int, 'rating':float})\n",
    "\n",
    "\n",
    "    def count_movies(self):\n",
    "        \"\"\"2. Print the number of movies in the dataset.\"\"\"\n",
    "\n",
    "        print('Number of movies in the dataset: ' + str(len(self.movies)))\n",
    "\n",
    "\n",
    "    def avg_rating(self):\n",
    "        \"\"\"3. Print the average rating of all the movies.\"\"\"\n",
    "        \n",
    "        average_rating = self.ratings['rating'].mean()\n",
    "        print('Average movie rating: ' + str(np.round(average_rating, 2)))\n",
    "\n",
    "\n",
    "    def top_5_movies(self):\n",
    "        \"\"\"4. Print the top 5 highest rated movies.\"\"\"\n",
    "        \n",
    "        # Calculate the average ratign by movieId\n",
    "        avg_ratings_df = self.ratings.groupby('movieId').apply('mean', 'rating')\n",
    "\n",
    "        # Merge the dataframes based on ratingsmovieId and id\n",
    "        merged_df = pd.merge(avg_ratings_df, self.movies, left_index=True, right_index=True)\n",
    "        \n",
    "        # Calculate the top 5 movies\n",
    "        top_5_movies = merged_df[['rating', 'title']].sort_values('rating', ascending=False).head(5)\n",
    "        \n",
    "        # print('Top 5 movies:' + str(top_5_movies))\n",
    "        \n",
    "        return top_5_movies    \n",
    "\n",
    "    \n",
    "    def movies_per_genre(self):\n",
    "        \"\"\"6. Print the number of movies in each genre.\"\"\"\n",
    "        \n",
    "        # Convert the string stored in column 'genres' to lists of dictionaries\n",
    "        if isinstance(self.movies['genres'].iloc[0], str):\n",
    "            self.movies['genres'] = self.movies['genres'].apply(ast.literal_eval)\n",
    "    \n",
    "        # Extract the relevant information from the nested dictionaries\n",
    "        self.movies['genre_names'] = self.movies['genres'].apply(lambda x: [genre['name'] for genre in x])\n",
    "        \n",
    "        # Count the number of movies per genre and convert to pandas.DataFrame\n",
    "        movies_per_genre = self.movies['genre_names'].explode().value_counts()\n",
    "        movies_per_genre.columns = ['Genre', 'Count']\n",
    "    \n",
    "        return movies_per_genre.to_frame().reset_index()    \n",
    "\n",
    "    \n",
    "    def movies_per_year(self):\n",
    "        \"\"\"5. Print the number of movies released each year.\"\"\"\n",
    "        \n",
    "        # Extract the year component from 'release_date' and store into a new column 'release_year'\n",
    "        self.movies['release_year'] = pd.to_datetime(self.movies['release_date'], errors='coerce').dt.year\n",
    "        \n",
    "        # Drop the `na` in 'release_year'\n",
    "        self.movies['release_year'] = self.movies['release_year'].dropna()\n",
    "        \n",
    "        # Count the number of movies released each year\n",
    "        movies_per_year = self.movies['release_year'].value_counts().sort_index()\n",
    "        \n",
    "        # Create a movies_per_year_df pandas.DataFrame from the pandas.Series\n",
    "        movies_per_year_df = pd.DataFrame({'Year': movies_per_year.index, 'Count': movies_per_year.values})\n",
    "        \n",
    "        # Cast 'Year' column to integer data type\n",
    "        movies_per_year_df['Year'] = movies_per_year_df['Year'].astype(int)\n",
    "    \n",
    "        return movies_per_year_df\n",
    "    \n",
    "    \n",
    "    def save_to_json(self, result, filepath):\n",
    "        \"\"\"7. Save the dataset to a JSON file.\"\"\"\n",
    "        \n",
    "        result.to_json(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f46677",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_filepath = 'data/movies_metadata.csv'\n",
    "ratings_filepath = 'data/ratings.csv'\n",
    "\n",
    "# Create an instance of the MoviesAnalysis class\n",
    "movies_analysis = MoviesAnalisys(movies_filepath, ratings_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0915cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the number of movies in the dataset\n",
    "movies_count = movies_analysis.count_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b992339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average rating of all movies\n",
    "average_rating = movies_analysis.avg_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f132c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top 5 movies\n",
    "top_5_movies_result = movies_analysis.top_5_movies()\n",
    "top_5_movies_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of movies in each genre\n",
    "movies_per_genre_result = movies_analysis.movies_per_genre()\n",
    "movies_per_genre_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of movies released each year\n",
    "movies_per_year_result = movies_analysis.movies_per_year()\n",
    "movies_per_year_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834843a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store some of the reulting dataframes as JSON files\n",
    "top_5_movies_result_filepath = 'results_json/top_5_movies.json'\n",
    "movies_per_genre_result_filepath = 'results_json/movies_per_genre.json'\n",
    "movies_per_year_result_filepath = 'results_json/movies_per_year.json'\n",
    "\n",
    "movies_analysis.save_to_json(top_5_movies_result, top_5_movies_result_filepath)\n",
    "movies_analysis.save_to_json(movies_per_genre_result, movies_per_genre_result_filepath)\n",
    "movies_analysis.save_to_json(movies_per_year_result, movies_per_year_result_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dcbf33",
   "metadata": {},
   "source": [
    "## 8. Improved implementation of the OOP featuring an explicit data-centered workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc3a4d",
   "metadata": {},
   "source": [
    "This new implementation over the previous one promotes modularity, explicit data flow, improved reusability and readability. All these improvement are made with the intention to make the code easier to use and maintain.\n",
    "\n",
    "- **Modularity**: in the new implementation the program is divided in a set of classes (`DataIO`, `DataCleaning` and `DataAnalysis`), each responsible for a set of specific tasks. \n",
    "\n",
    "- **Explicit workflow**: the new implementation follows and explicit data-centered workflow, starting from `DataIO` class for reading and writing data, which then passes the data to `DataCleaning` class for data preprocessing and cleaning and finally to the `DataAnalysis` class for various data analysis tasks. This makes the code more logical, easier to understand and maintain.\n",
    "\n",
    "- **Code reusability**: each class has well defined methods, which can be used in other projects and parts of the program. For example, the data cleaning methods can be reused in different analysis tasks without modifying the original class.\n",
    "\n",
    "- **Readability and Debugging**: The new implementation is more readable and easier to debug due to its functional organisation (explicit data-first workflow). Each class is responsible for a specific part of the process, making it easier to locate and fix issues if they arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68275e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from datetime import datetime, date\n",
    "\n",
    "\n",
    "class DataIO():\n",
    "    \"\"\"Data input-output (reading from and writing to file)\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, movies_filepath, ratings_filepath):\n",
    "        \"\"\"Initialize attributes\"\"\"\n",
    "        self.ratings_filepath = ratings_filepath\n",
    "        self.movies_filepath = movies_filepath\n",
    "        self.movies_df = pd.DataFrame()\n",
    "        self.ratings_df = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "    def read_data(self):\n",
    "        # 1. Load the dataset from a CSV file.\n",
    "        # Define the data types for each column\n",
    "        dtypes_movies = {\n",
    "            'genres': object,\n",
    "            'release_date': str,\n",
    "            'title': str,\n",
    "        }\n",
    "        \n",
    "        # Read the movies_metadata.csv file\n",
    "        movies_columns = ['genres', 'id', 'release_date', 'title']\n",
    "        self.movies_df = pd.read_csv(movies_filepath, header=0, sep=',', \\\n",
    "                                     parse_dates=True, \\\n",
    "                                     usecols=movies_columns, \\\n",
    "                                     dtype=dtypes_movies)\n",
    "        \n",
    "        \n",
    "        # Read the ratings.csv file\n",
    "        ratings_columns = ['movieId', 'rating']\n",
    "        self.ratings_df = pd.read_csv(ratings_filepath, \\\n",
    "                                   usecols=ratings_columns, \\\n",
    "                                   index_col='movieId', \\\n",
    "                                   dtype={'movieId': int, 'rating':float})\n",
    "        \n",
    "\n",
    "        return self.movies_df, self.ratings_df\n",
    "\n",
    "\n",
    "    def write_data(self, result, filepath):\n",
    "        \"\"\"7. Save the dataset to a JSON file.\"\"\"\n",
    "        \n",
    "        result.to_json(filepath)\n",
    "\n",
    "\n",
    "\n",
    "class DataCleaning():\n",
    "    \"\"\"Data cleaning and preprocessing\"\"\"\n",
    "\n",
    "    def __init__(self, movies_df, ratings_df):\n",
    "        \"\"\"Initialize attributes\"\"\"\n",
    "        self.movies_df = movies_df\n",
    "        self.ratings_df = ratings_df\n",
    "\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"Clean the data before analysis\"\"\"\n",
    "        \n",
    "        # Drop the non-alphanumeric rows\n",
    "        self.movies_df = self.movies_df[self.movies_df['id'].str.isalnum()]\n",
    "        \n",
    "        # Keep only the rows with unique 'id' numbers\n",
    "        self.movies_df = self.movies_df.drop_duplicates(subset='id')\n",
    "        \n",
    "        # Convert 'id' column to int data type\n",
    "        self.movies_df['id'] = self.movies_df['id'].astype(int)\n",
    "        \n",
    "        # Set the 'id' column as self.movies index\n",
    "        self.movies_df.set_index('id', inplace=True)\n",
    "        \n",
    "        return self.movies_df\n",
    "\n",
    "\n",
    "\n",
    "class DataAnalisys():\n",
    "    \"\"\"Data analysis of the movies dataset\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, ratings_df, movies_df):\n",
    "        \"\"\"Initialize attributes\"\"\"\n",
    "        self.movies_df = movies_df\n",
    "        self.ratings_df = ratings_df\n",
    "\n",
    "\n",
    "    def count_movies(self):\n",
    "        \"\"\"2. Print the number of movies in the dataset.\"\"\"\n",
    "        print('Number of movies in the dataset: ' + str(len(self.movies_df)))\n",
    "\n",
    "\n",
    "    def avg_rating(self):\n",
    "        \"\"\"3. Print the average rating of all the movies.\"\"\"        \n",
    "        average_rating = self.ratings_df['rating'].mean()\n",
    "        print('Average movie rating: ' + str(np.round(average_rating, 2)))\n",
    "\n",
    "\n",
    "    def top_5_movies(self):\n",
    "        \"\"\"4. Print the top 5 highest rated movies.\"\"\"\n",
    "        \n",
    "        # Calculate the average ratign by movieId\n",
    "        avg_ratings_df = self.ratings_df.groupby('movieId').apply('mean', 'rating')\n",
    "\n",
    "        # Merge the dataframes based on ratingsmovieId and id\n",
    "        merged_df = pd.merge(avg_ratings_df, self.movies_df, left_index=True, right_index=True)\n",
    "        \n",
    "        # Calculate the top 5 movies\n",
    "        top_5_movies = merged_df[['rating', 'title']].sort_values('rating', ascending=False).head(5)\n",
    "        \n",
    "        # print('Top 5 movies:' + str(top_5_movies))\n",
    "        \n",
    "        return top_5_movies    \n",
    "\n",
    "    \n",
    "    def movies_per_genre(self):\n",
    "        \"\"\"6. Print the number of movies in each genre.\"\"\"\n",
    "        \n",
    "        # Convert the string stored in column 'genres' to lists of dictionaries\n",
    "        if isinstance(self.movies_df['genres'].iloc[0], str):\n",
    "            self.movies_df['genres'] = self.movies_df['genres'].apply(ast.literal_eval)\n",
    "    \n",
    "        # Extract the relevant information from the nested dictionaries\n",
    "        self.movies_df['genre_names'] = self.movies_df['genres'].apply(lambda x: [genre['name'] for genre in x])\n",
    "        \n",
    "        # Count the number of movies per genre and convert to pandas.DataFrame\n",
    "        movies_per_genre = self.movies_df['genre_names'].explode().value_counts()\n",
    "        movies_per_genre.columns = ['Genre', 'Count']\n",
    "    \n",
    "        return movies_per_genre.to_frame().reset_index()    \n",
    "\n",
    "    \n",
    "    def movies_per_year(self):\n",
    "        \"\"\"5. Print the number of movies released each year.\"\"\"\n",
    "        \n",
    "        # Extract the year component from 'release_date' and store into a new column 'release_year'\n",
    "        self.movies_df['release_year'] = pd.to_datetime(self.movies_df['release_date'], errors='coerce').dt.year\n",
    "        \n",
    "        # Drop the `na` in 'release_year'\n",
    "        self.movies_df['release_year'] = self.movies_df['release_year'].dropna()\n",
    "        \n",
    "        # Count the number of movies released each year\n",
    "        movies_per_year = self.movies_df['release_year'].value_counts().sort_index()\n",
    "        \n",
    "        # Create a movies_per_year_df pandas.DataFrame from the pandas.Series\n",
    "        movies_per_year_df = pd.DataFrame({'Year': movies_per_year.index, 'Count': movies_per_year.values})\n",
    "        \n",
    "        # Cast 'Year' column to integer data type\n",
    "        movies_per_year_df['Year'] = movies_per_year_df['Year'].astype(int)\n",
    "    \n",
    "        return movies_per_year_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86705e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_filepath = 'data/movies_metadata.csv'\n",
    "ratings_filepath = 'data/ratings.csv'\n",
    "\n",
    "# Create a data_io object and initialize it with filepaths\n",
    "data_io = DataIO(movies_filepath, ratings_filepath)\n",
    "\n",
    "# Read the data from the files\n",
    "movies_df, ratings_df = data_io.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f5ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data_cleaning object and initialize it with DataFrames\n",
    "data_cleaning = DataCleaning(ratings_df=ratings_df, movies_df=movies_df)\n",
    "\n",
    "# Call the clean_data method on movies_df\n",
    "movies_df = data_cleaning.clean_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc271bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies in the dataset: 45433\n"
     ]
    }
   ],
   "source": [
    "# Create a data_analysis object and initialize it with DataFrames\n",
    "data_analysis = DataAnalisys(ratings_df=ratings_df, movies_df=movies_df)\n",
    "\n",
    "# 2. Print the number of movies in the dataset.\n",
    "data_analysis.count_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780bc243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average movie rating: 3.53\n"
     ]
    }
   ],
   "source": [
    "# 3. Print the average rating of all the movies\n",
    "data_analysis.avg_rating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866e64c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95977</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The Man Behind The Gun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167666</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Monster High: Escape from Skull Shores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130544</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Palermo or Wolfsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129530</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Brutal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164278</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Harvey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating                                   title\n",
       "95977      5.0                  The Man Behind The Gun\n",
       "167666     5.0  Monster High: Escape from Skull Shores\n",
       "130544     5.0                    Palermo or Wolfsburg\n",
       "129530     5.0                                  Brutal\n",
       "164278     5.0                                  Harvey"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Print the top 5 highest rated movies.\n",
    "data_analysis.top_5_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c478d9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_names</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drama</td>\n",
       "      <td>20244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>13176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romance</td>\n",
       "      <td>6730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action</td>\n",
       "      <td>6592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horror</td>\n",
       "      <td>4671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Crime</td>\n",
       "      <td>4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>3930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Family</td>\n",
       "      <td>2767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animation</td>\n",
       "      <td>1931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>1619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Music</td>\n",
       "      <td>1597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>History</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>War</td>\n",
       "      <td>1322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Western</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TV Movie</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        genre_names  count\n",
       "0             Drama  20244\n",
       "1            Comedy  13176\n",
       "2          Thriller   7619\n",
       "3           Romance   6730\n",
       "4            Action   6592\n",
       "5            Horror   4671\n",
       "6             Crime   4304\n",
       "7       Documentary   3930\n",
       "8         Adventure   3490\n",
       "9   Science Fiction   3044\n",
       "10           Family   2767\n",
       "11          Mystery   2464\n",
       "12          Fantasy   2309\n",
       "13        Animation   1931\n",
       "14          Foreign   1619\n",
       "15            Music   1597\n",
       "16          History   1398\n",
       "17              War   1322\n",
       "18          Western   1042\n",
       "19         TV Movie    766"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Print the number of movies in each genre\n",
    "data_analysis.movies_per_genre()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d96f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1887</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1888</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2015</td>\n",
       "      <td>1904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2016</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2017</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Count\n",
       "0    1874      1\n",
       "1    1878      1\n",
       "2    1883      1\n",
       "3    1887      1\n",
       "4    1888      2\n",
       "..    ...    ...\n",
       "130  2015   1904\n",
       "131  2016   1604\n",
       "132  2017    532\n",
       "133  2018      5\n",
       "134  2020      1\n",
       "\n",
       "[135 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Print the number of movies released each year\n",
    "data_analysis.movies_per_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502d9ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
